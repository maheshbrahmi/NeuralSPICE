{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import torch  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.head(4))\n",
    "# Separate features and target\n",
    "X = df[[\"VC\", \"VB\", \"IB\"]].values\n",
    "y = df[\"IC\"].values.reshape(-1, 1)\n",
    "\n",
    "# Create train/validation/test splits (80/10/10)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1234)\n",
    "\n",
    "# Save X_test and y_test to a file for later use\n",
    "test_data = pd.DataFrame(X_test, columns=[\"VC\", \"VB\", \"IB\"])\n",
    "test_data[\"IC\"] = y_test  # Add the target column\n",
    "test_data.to_csv(\"test_data_.csv\", index=False)\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Fit on training data, transform all sets\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "X_val = scaler_X.transform(X_val)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Save scalers for later inference\n",
    "joblib.dump(scaler_X, 'scaler_X_.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y_.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATE MODEL, TRAIN AND SAVE THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Architecture\n",
    "class BJTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3, 256),  # Input: 3 features (VC, VB, IB)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)     # Output: Predicted IC\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Create model instance\n",
    "model = BJTModel()\n",
    "\n",
    "# Prepare data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "EPOCHS = 100\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "    #print(f\"Epoch {epoch+1}: Validation Loss = {val_loss:.6f}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}\")\n",
    "    \n",
    "    # Uncomment below to activate early stopping\n",
    "        # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model_test_.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"bjt_model_.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model, load scaler and test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Define your model class and load its instance if not already done so\n",
    "# class BJTModel(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BJTModel, self).__init__()\n",
    "#         self.layers = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(3, 256),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(256, 128),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(128, 64),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(64, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "\n",
    "# # Initialize the model\n",
    "# model = BJTModel()\n",
    "\n",
    "# 1. Load the trained model\n",
    "model.load_state_dict(torch.load('bjt_model_.pth'))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# 2. Load test data and scalers\n",
    "test_df = pd.read_csv('test_data_.csv')\n",
    "scaler_X = joblib.load('scaler_X_.pkl')\n",
    "scaler_y = joblib.load('scaler_y_.pkl')\n",
    "\n",
    "# 3. Prepare test data\n",
    "X_test = test_df[[\"VC\", \"VB\", \"IB\"]].values\n",
    "y_test = test_df[\"IC\"].values.reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 4. Define inference function\n",
    "def predict_ic(vc, vb, ib):\n",
    "    \"\"\"Predict collector current (IC) given VC, VB, and IB values\"\"\"\n",
    "    # Prepare input data\n",
    "    input_data = np.array([[vc, vb, ib]], dtype=np.float32)\n",
    "    input_scaled = scaler_X.transform(input_data)\n",
    "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(input_tensor)\n",
    "    \n",
    "    # Convert back to original scale\n",
    "    return scaler_y.inverse_transform(pred_scaled.numpy())[0][0]\n",
    "\n",
    "# 5. Evaluate model on test data\n",
    "VC_list, VB_list, IB_list = [], [], []\n",
    "IC_actual, IC_predicted = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        # Extract values from current batch\n",
    "        VC_batch = x[:, 0].numpy()\n",
    "        VB_batch = x[:, 1].numpy()\n",
    "        IB_batch = x[:, 2].numpy()\n",
    "        IC_batch = y.numpy().flatten()\n",
    "        \n",
    "        # Make predictions for each data point\n",
    "        for VC, VB, IB in zip(VC_batch, VB_batch, IB_batch):\n",
    "            predicted = predict_ic(VC, VB, IB)\n",
    "            \n",
    "            # Store values\n",
    "            VC_list.append(VC)\n",
    "            VB_list.append(VB)\n",
    "            IB_list.append(IB)\n",
    "            IC_predicted.append(predicted)\n",
    "        \n",
    "        IC_actual.extend(IC_batch)\n",
    "\n",
    "# 6. Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'VC': VC_list,\n",
    "    'VB': VB_list,\n",
    "    'IB': IB_list,\n",
    "    'IC_Actual': IC_actual,\n",
    "    'IC_Predicted': IC_predicted\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots with enhance styling and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualize results with enhanced styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Use seaborn style for a clean look\n",
    "\n",
    "# Set consistent color palette\n",
    "COLORS = {'measured': '#E63946', 'predicted': '#1D3557', 'background': '#F1FAEE'}\n",
    "\n",
    "# Plot 1: Comparison of actual vs predicted for a subset of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "sample_range = slice(500, 700)  # Visualize a subset of points\n",
    "x_indices = range(len(results_df))[sample_range]\n",
    "\n",
    "# Add light background\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor(COLORS['background'])\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(x_indices, results_df['IC_Actual'][sample_range], \n",
    "            color=COLORS['measured'], s=30, label='Measured IC', alpha=0.9)\n",
    "plt.scatter(x_indices, results_df['IC_Predicted'][sample_range], \n",
    "            color=COLORS['predicted'], marker='s', s=25, alpha=0.7, label='Neural Network Prediction')\n",
    "\n",
    "# Improve styling\n",
    "plt.title('Neural Network Model Predictions vs. Measured Values', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Test Data Point Index', fontsize=12)\n",
    "plt.ylabel('Collector Current IC (A)', fontsize=12)\n",
    "plt.legend(frameon=True, facecolor='white', edgecolor='gray')\n",
    "plt.tight_layout()\n",
    "plt.savefig('bjt_predictions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOT IV CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: IV curve for a specific base current\n",
    "target_ib = 2.0e-05  # Target base current (20 µA)\n",
    "tolerance = 0.01e-6  # Tolerance for selecting points\n",
    "\n",
    "# Filter data points with the specified base current\n",
    "selected_data = results_df[(results_df['IB'] >= target_ib - tolerance) &\n",
    "                          (results_df['IB'] <= target_ib + tolerance)]\n",
    "selected_data_sorted = selected_data.sort_values(by='VC')\n",
    "\n",
    "# Plot IV curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(selected_data_sorted['VC'], selected_data_sorted['IC_Actual'],\n",
    "         label='Measured Data')\n",
    "plt.plot(selected_data_sorted['VC'], selected_data_sorted['IC_Predicted'],\n",
    "         label='Neural Network Model', linestyle='--')\n",
    "\n",
    "plt.xlabel('Collector Voltage VC (V)')\n",
    "plt.ylabel('Collector Current IC (A)')\n",
    "plt.title(f'IV Curve at Base Current IB ≈ {target_ib:.2e} A')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLOT IV CURVES (MULTIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of base currents to plot\n",
    "base_currents = np.array([10, 20, 30, 40, 50, 60]) * 1e-6  # in amperes\n",
    "tolerance = 0.5e-6  # Tolerance for filtering data points\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate IV curves for each base current\n",
    "for ib in base_currents:\n",
    "    # Filter data points with the specified base current\n",
    "    selected_data = results_df[(results_df['IB'] >= ib - tolerance) & \n",
    "                              (results_df['IB'] <= ib + tolerance)]\n",
    "    \n",
    "    if len(selected_data) > 0:\n",
    "        # Sort by collector voltage for proper curve plotting\n",
    "        selected_data_sorted = selected_data.sort_values(by='VC')\n",
    "        \n",
    "        # Plot measured data\n",
    "        plt.plot(selected_data_sorted['VC'], selected_data_sorted['IC_Actual'],\n",
    "                 label=f'Measured: IB = {ib*1e6:.1f} µA')\n",
    "        \n",
    "        # Plot neural network predictions (dashed lines)\n",
    "        plt.plot(selected_data_sorted['VC'], selected_data_sorted['IC_Predicted'],\n",
    "                 linestyle='--', label=f'NN Model: IB = {ib*1e6:.1f} µA')\n",
    "\n",
    "plt.xlabel('Collector-Emitter Voltage, VCE (V)')\n",
    "plt.ylabel('Collector Current, IC (A)')\n",
    "plt.title('BJT Characteristic Curves: Measured vs. Neural Network Model')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Part 1 END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPARE WITH PYSPICE SIMULATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1. Create the Transistor Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySpice.Spice.Netlist import Circuit\n",
    "from PySpice.Unit import u_uA, u_uV, u_V\n",
    "\n",
    "def create_transistor_circuit(base_current=10):\n",
    "    circuit = Circuit('Transistor')\n",
    "    Ibase = circuit.I('base', circuit.gnd, 'base', base_current@u_uA)\n",
    "    Vcollector = circuit.V('collector', 'collector', circuit.gnd, 5@u_V)\n",
    "    circuit.BJT(1, 'collector', 'base', circuit.gnd, model='2n2222')\n",
    "    # Define the model parameters\n",
    "    circuit.model('2n2222', 'npn', IS=1E-14, VAF=100, BF=205, IKF=0.3, XTB=1.5, BR=3, CJC=8E-12, \n",
    "                  CJE=25E-12, TR=100E-9, TF=400E-12, ITF=1, VTF=2, XTF=3, RB=10, RC=0.3, RE=0.2)\n",
    "    return circuit\n",
    "\n",
    "circuit = create_transistor_circuit(base_current=10)\n",
    "print(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Run the VC Vs IC Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store simulation results\n",
    "VC, VB, IB, IC = [], [], [], []\n",
    "base_current_range = np.arange(10, 70, 10)\n",
    "# Create circuit and run simulations\n",
    "circuit = create_transistor_circuit()\n",
    "for base_current in base_current_range:\n",
    "    # Update base current\n",
    "    ib_value = base_current * 1e-6\n",
    "    circuit.Ibase.dc_value = base_current@u_uA\n",
    "    \n",
    "    # Run DC sweep\n",
    "    simulator = circuit.simulator(temperature=27, nominal_temperature=27)\n",
    "    analysis = simulator.dc(Vcollector=slice(0, 5.00, 0.01))\n",
    "    \n",
    "    # Extract results\n",
    "    for i in range(len(analysis.Vcollector)):\n",
    "        VC.append(float(analysis.collector[i]))\n",
    "        VB.append(float(analysis.base[i]))\n",
    "        IB.append(ib_value)\n",
    "        IC.append(float(-analysis.Vcollector[i]))\n",
    "\n",
    "# Create DataFrame with results\n",
    "df_sim = pd.DataFrame({'VC': VC, 'VB': VB, 'IB': IB, 'IC': IC})\n",
    "print(df_sim.head(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 Neural Network Integration\n",
    "The neural network model is used as a predictive proxy for the BJT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def neural_network_simulation(model, df_sim):\n",
    "    # Create input features from simulation data\n",
    "    X = df_sim[['VC', 'VB', 'IB']].values\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    \n",
    "    # Make predictions with the neural network\n",
    "    with torch.no_grad():\n",
    "        IC_pred = model(X_tensor).numpy()\n",
    "    \n",
    "    # Create new DataFrame with predictions\n",
    "    df_nn = df_sim.copy()\n",
    "    df_nn['IC_Predicted'] = IC_pred\n",
    "    \n",
    "    return df_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(df, selected_ib_values, tolerance=0.5e-6, max_vc=5):\n",
    "    # Filter for selected IB values\n",
    "    filtered_df = pd.DataFrame()\n",
    "    for target_ib in selected_ib_values:\n",
    "        selected_group = df[(df['IB'] >= target_ib - tolerance) & \n",
    "                            (df['IB'] <= target_ib + tolerance)]\n",
    "        filtered_df = pd.concat([filtered_df, selected_group])\n",
    "    \n",
    "    # Remove rows with VC values greater than max_vc\n",
    "    filtered_df = filtered_df[filtered_df['VC'] <= max_vc]\n",
    "    \n",
    "    # Sort by VC\n",
    "    return filtered_df.sort_values(by='VC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.Create Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(sim_df, nn_df, selected_ib_values, tolerance=0.5e-6):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_title('Collector Current vs Collector-Emitter Voltage for Different Base Currents')\n",
    "    ax.set_xlabel('Collector-Emitter Voltage, VCE [V]')\n",
    "    ax.set_ylabel('Collector Current, IC [A]')\n",
    "    \n",
    "    # Plot PySpice results (solid lines)\n",
    "    for target_ib in selected_ib_values:\n",
    "        selected_group = sim_df[(sim_df['IB'] >= target_ib - tolerance) & \n",
    "                               (sim_df['IB'] <= target_ib + tolerance)]\n",
    "        ax.plot(selected_group['VC'], selected_group['IC'],\n",
    "                label=f'PySpice: IB = {(target_ib*1e6):.1f} μA')\n",
    "    \n",
    "    # Plot Neural Network predictions (dashed lines)\n",
    "    for target_ib in selected_ib_values:\n",
    "        selected_group = nn_df[(nn_df['IB'] >= target_ib - tolerance) & \n",
    "                              (nn_df['IB'] <= target_ib + tolerance)]\n",
    "        ax.plot(selected_group['VC'], selected_group['IC_Predicted'],\n",
    "                linestyle='--', label=f'NN Model: IB = {(target_ib*1e6):.1f} μA')\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='right')\n",
    "    plt.tight_layout()\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize PySpice and Neural Network Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_ib_values = np.array([60e-6, 80e-6])  # 60μA and 80μA\n",
    "selected_ib_values = np.arange(10e-6, 70e-6, 10e-6)\n",
    "    \n",
    "# 3. Filter simulation results\n",
    "filtered_sim_df = filter_results(df_sim, selected_ib_values)\n",
    "\n",
    "# 4. Filter Neural Network results\n",
    "filtered_nn_df = filter_results(results_df, selected_ib_values)\n",
    "\n",
    "plot_comparison(filtered_sim_df, filtered_nn_df, selected_ib_values, tolerance=0.5e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
